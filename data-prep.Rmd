---
title: "Data preparation"
output:
  pdf_document: default
---

# Instructions

- You only need to submit the .Rmd of this file, not a PDF.

- You should __comment__ your code clearly to show what you've done to prepare the data.

- The purpose of this file is to use the data in the `data-raw` folder to create the data you will use in the report. The data you will use in the report should be saved in the `data` folder. It is good professional practice to make sure you're never directly modifying your raw data, but instead creating new datasets based on merges/manipulations that you need to reuse.

- Make sure you've taken a look at the hints for the web scraping and census API. 

- You may find the `write_rds()` function from the `readr` package helpful (it is loaded as part of the `tidyverse`).

- You do not need to keep the structure below.


# Set up

```{r}
install.packages("cancensus")
```


```{r, libraries}
# Set up any libraries you need
library(tidyverse)
library(polite)
library(rvest)
library(cancensus)
library(dplyr)
```



# Loading client data

```{r}


# data linking customer to device
cust_dev <- read_rds("data-raw/cust_dev.Rds")

# data for device
device <- read_rds("data-raw/device.Rds")

# data for customers
customer <- read_rds("data-raw/customer.Rds")

# data for customer sleep information
cust_sleep <- read_rds("data-raw/cust_sleep.Rds")

# post data was used due to time manageent difficulties :(
postal <- read_rds("data-raw/break_glass_in_case_of_emergency.Rds")


```

# Getting external data

## Web scraping industry data

```{r}

url <- "https://fitnesstrackerinfohub.netlify.app/"

# Make sure this code is updated appropriately to provide 
# informative user_agent details

target <- bow(url,
              user_agent = "hamz.khan@mail.utoronto.ca for STA303/1002 project",
              force = TRUE)

# Any details provided in the robots text on crawl delays and 
# which agents are allowed to scrape
target

html <- scrape(target)

device_data <- html %>% 
  html_elements("table") %>% 
  html_table() %>% 
  pluck(1) # added, in case you're getting a list format

```

# Census API

```{r}

options(cancensus.api_key = "CensusMapper_64a00caccae615e871e38d76fb598d32",
        cancensus.cache_path = "cache") # this sets a folder for your cache


# get all regions as at the 2016 Census (2020 not up yet)
regions <- list_census_regions(dataset = "CA16")

regions_filtered <-  regions %>% 
  filter(level == "CSD") %>% # Figure out what CSD means in Census data
  as_census_region_list()

# This can take a while
# We want to get household median income
census_data_csd <- get_census(dataset='CA16', regions = regions_filtered,
                          vectors=c("v_CA16_2397"), 
                          level='CSD', geo_format = "sf")

# Simplify to only needed variables
median_income <- census_data_csd %>% 
  as_tibble() %>% 
  select(CSDuid = GeoUID, contains("median"), Population) %>% 
  mutate(CSDuid = parse_number(CSDuid)) %>% 
  rename(hhld_median_inc = 2)

```
# Data Cleaning

```{r}

# adding age variable
customer <- customer %>%
  mutate(dob = as.Date(dob,'%Y-%m-%d')) %>%
  mutate(age = as.numeric(difftime(Sys.Date(),dob, units = "weeks"))/52.25) %>%
  drop_na(sex, pronouns) # drop NAs for irrelevant variables


# changing emoji modifer code to actual words for ease of interpretation
customer <- customer %>%
  mutate(emoji_modifier =
           if_else(emoji_modifier=="U+1F3FB", "light skin tone",
                   if_else(emoji_modifier=="U+1F3FC","medium-light skin tone",
                           if_else(emoji_modifier=="U+1F3FD","medium skin tone",
                                   if_else(emoji_modifier=="U+1F3FE",
                                           "medium-dark skin tone", if_else(
                                             emoji_modifier=="U+1F3FF",
                                  "dark skin tone", emoji_modifier))))))
#changing NAs to default
customer <- customer %>%
  mutate(emoji_modifier = if_else(is.na(emoji_modifier),
                                  'Default', emoji_modifier)) %>%
  drop_na(sex, pronouns)


# only keep distin
postal <- postal %>%
  distinct(CSDuid, PC)

median_income <- median_income %>%
  distinct(CSDuid, hhld_median_inc)

# merging datasets 
income_postal <- inner_join(x= median_income, y=postal, by="CSDuid")

customer_incpost <- left_join(x= customer, y= income_postal, by = c("postcode" = "PC"))


cust_dev_inc <- inner_join(x= cust_dev, y=customer_incpost, by="cust_id")

cust_final <- inner_join(x= cust_dev_inc, y=device, by="dev_id")

cust_final <- cust_final %>%
  select(sex, pronouns, emoji_modifier, age, hhld_median_inc, device_name, line, released) %>%
  subset(select=-c(cust_id))



```

```{r}

dev_sleep <- device_data %>%
  select(`Device name`, Line, `Recommended retail price`, `Battery life`) %>%
  rename(device_name = `Device name`, line = Line, retail_price = `Recommended retail price`, bat_life = `Battery life`)

dev_sleep <- left_join(device, dev_sleep, by=c("device_name" = "device_name", "line" = "line"))

```

```{r}

cust_sleep_final <- left_join(cust_sleep, customer, by="cust_id")
cust_sleep_final <- left_join(cust_sleep_final, cust_dev, by="cust_id")
cust_sleep_final <- left_join(cust_sleep_final, dev_sleep, by="dev_id")

cust_sleep_final <- cust_sleep_final %>%
  subset(select=-c(dev_id, released)) %>%
  drop_na(sex, pronouns, postcode)
```


# Adding to Data folder


```{r}

#Adding rds to data folder

write_rds(x=cust_final, file="data/cust_dev_info.Rds")
write_rds(dev_sleep, "data/dev_sleep.Rds")
write_rds(cust_sleep_final, "data/cust_sleep.Rds")
```





